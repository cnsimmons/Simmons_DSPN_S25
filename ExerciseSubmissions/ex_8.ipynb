{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cnsimmons/Simmons_DSPN_S25/blob/master/ExerciseSubmissions/ex_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szkkhiCZDF52"
      },
      "source": [
        "# Exercise 8:  Linear models, continued\n",
        "\n",
        "This homework assignment is designed to give you a deeper understanding of linear models. First, we'll dive into the math behind the closed-form solution of maximum likelihood estimation. **In the first section below, write your answers using Latex equation formatting.**\n",
        "\n",
        "*Note: Check out [this page](https://gtribello.github.io/mathNET/assets/notebook-writing.html) and [this page](https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd) for resources on how to do Latex formatting. You can also double click on the question cells in this notebook to see how math is formatted in the questions.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Deriving the Maximum Likelihood Estimate for Simple Linear Regression 3/6: correct answers see below\n",
        "\n",
        "\n",
        "\n",
        "2. Connecting to data 4/4\n",
        "\n"
      ],
      "metadata": {
        "id": "Rq7fv6Az9HN-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJscNReoylRt"
      },
      "source": [
        "---\n",
        "## 1. Deriving the Maximum Likelihood Estimate for Simple Linear Regression (6 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH82gwuymPi0"
      },
      "source": [
        "Using the mean squared error (MSE) as your objective function (the thing you're trying to minimize when you fit your model) allows for a closed form solution to finding the maximum likelihood estimate (MLE) of your model parameters in linear regression. Let’s consider the simple, single predictor variable model, i.e. simple linear regression :  $Y= \\beta_0 + \\beta_1 X $.\n",
        "\n",
        "a) Use algebra to show how you can expand out $MSE(\\beta_0, \\beta_1)$ to get from i to ii below.\n",
        "\n",
        "> _i)_ $E[ (Y-(\\beta_0 + \\beta_1 X))^2]$\n",
        "\n",
        "> _ii)_ $E[Y^2] -2 \\beta_0E[Y]-2 \\beta_1 Cov[X,Y]-2 \\beta_1 E[X]E[Y]+ \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]+\\beta_1^2 Var[X]+ \\beta_1^2 (E[X])^2$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn2hveNho-Of"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        ">_i)_ $E[ (Y-(\\beta_0 + \\beta_1 X))^2]$ is expanded with square: *E*[(yi​)2−2yi​(β0​+β1​xi​)+(β0​+β1​xi​)2]\n",
        "which is further expanded to: E[yi2​−2β0​yi​−2β1​xi​yi​+β02​+2β0​β1​xi​+β12​xi2​] ending with form ii."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correct answer a)"
      ],
      "metadata": {
        "id": "f6syZzyB9Z1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{eqnarray}\n",
        " MSE(\\beta_0,\\beta_1) &=& E[ (Y-(\\beta_0 + \\beta_1 X))^2]  \\\\\n",
        "   &=& E[(Y-(\\beta_0 + \\beta_1X))(Y-(\\beta_0+\\beta_1X))] \\\\\n",
        "   &=& E[Y^2 - 2Y(\\beta_0 + \\beta_1X) + (\\beta_0 + \\beta_1X)^2] \\\\\n",
        "   &=& E[Y^2 - 2Y\\beta_0 -2Y\\beta_1X + (\\beta_0 + \\beta_1X)^2] \\\\\n",
        "   &=& E[Y^2] - 2\\beta_0E[Y] - 2\\beta_1E[XY] + E[(\\beta_0 + \\beta_1 X)^2] \\\\\n",
        "   &=& E[Y^2] - 2\\beta_0E[Y] - 2\\beta_1(Cov[XY] + E[X]E[Y]) + E[(\\beta_0 + \\beta_1 X)(\\beta_0 + \\beta_1 X)] \\\\\n",
        "   &=& E[Y^2] - 2\\beta_0E[Y] - 2\\beta_1(Cov[XY] + E[X]E[Y]) + E[\\beta_0^2 + 2\\beta_0\\beta_1X + \\beta_1^2X^2] \\\\\n",
        "   &=& E[Y^2] - 2\\beta_0E[Y] - 2\\beta_1(Cov[XY] + E[X]E[Y]) + \\beta_0^2 + 2\\beta_0\\beta_1E[X] + \\beta_1^2E[X^2] \\\\\n",
        "   &=& E[Y^2] -2 \\beta_0E[Y]-2 \\beta_1 Cov[X,Y]-2 \\beta_1 E[X]E[Y]+ \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]+\\beta_1^2 Var[X]+ \\beta_1^2 (E[X])^2\n",
        "\\end{eqnarray}"
      ],
      "metadata": {
        "id": "vKzYZwRS9ckV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCr46r9xwRXP"
      },
      "source": [
        "b) Prove that the MLE of $\\beta_0$ is $E[Y]- \\beta_1 E[X]$ by taking the derivative of _ii_ above, with respect to $\\beta_0$, setting the derivative to zero, and solving for $\\beta_0$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul-PZyLbwTCQ"
      },
      "source": [
        "**Answer:**\n",
        "the expanded form: ∑[y_i² - 2β₀y_i - 2β₁x_iy_i + β₀² + 2β₀β₁x_i + β₁²x_i²]\n",
        "\n",
        "take the partial derivative: ∂/∂β₁ = ∑[-2x_iy_i + 2β₀x_i + 2β₁x_i²]\n",
        "\n",
        "set equal to zero: ∑[-2x_iy_i + 2β₀x_i + 2β₁x_i²] = 0\n",
        "\n",
        "simplify: ∑[-2x_iy_i + 2β₀x_i + 2β₁x_i²] = 0\n",
        "\n",
        "solve for B: β₁∑x_i² = ∑x_iy_i - β₀∑x_i and β₁∑x_i² = ∑x_iy_i - β₀∑x_i"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correct answer b)"
      ],
      "metadata": {
        "id": "RFyJgeNg9p24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{eqnarray}\n",
        " \\frac{\\delta E[(Y-(\\beta_0 + \\beta_1X))^2]}{\\delta \\beta_0} &=& -2E[Y] + 2\\beta_0 + 2\\beta_1E[X]  \\\\\n",
        "   0 &=& -2E[Y] + 2\\beta_0 + 2\\beta_1E[X] \\\\\n",
        "   -2\\beta_0 &=& -2E[Y] + 2\\beta_1E[X] \\\\\n",
        "   \\beta_0 &=& E[Y] - \\beta_1E[X]\n",
        "\\end{eqnarray}"
      ],
      "metadata": {
        "id": "pRNOuLAC9w1v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uv4Z7afw4gB"
      },
      "source": [
        "c) Prove that the MLE for $\\beta_1$ is $Cov[X,Y]/Var[X]$ by taking the derivative of equation _ii_ above, with respect to $\\beta_1$, setting the derivative to zero, and solving for $\\beta_1$. *Hint: after you've simplified / expanded a bit, plug in the solution for $\\beta_0$ from part b.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWTFZ6ZSw6sh"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "take partial derivative with respct to B: β₁∑x_i² = ∑x_iy_i - β₀∑x_i\n",
        "\n",
        "set equal to zero: ∑[-2y_i + 2β₀ + 2β₁x_i] = 0\n",
        "\n",
        "simplify: -∑y_i + nβ₀ + β₁∑x_i = 0\n",
        "\n",
        "solve for B: nβ₀ = ∑y_i - β₁∑x_i\n",
        "            nβ₀ = ∑y_i - β₁∑x_i\n",
        "            β₀ = (∑y_i)/n - β₁(∑x_i)/n\n",
        "            β₀ = (∑y_i)/n - β₁(∑x_i)/n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correct answer c)"
      ],
      "metadata": {
        "id": "cX8e7vdV9ycF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{eqnarray}\n",
        " \\frac{\\delta E[(Y-(\\beta_0 + \\beta_1X))^2]}{\\beta_1} &=& -2Cov[XY] -2E[X]E[Y] + 2\\beta_0E[X] + 2\\beta_1Var[X] + 2\\beta_1(E[X])^2  \\\\\n",
        "   0 &=& -2Cov[XY] -2E[X]E[Y] + 2\\beta_0E[X] + 2\\beta_1Var[X] + 2\\beta_1(E[X])^2 \\\\\n",
        "   -2\\beta_1Var[X] - 2\\beta_1(E[X])^2 &=& -2Cov[XY] -2E[X]E[Y] + 2\\beta_0E[X] \\\\\n",
        "   -2\\beta_1Var[X] - 2\\beta_1(E[X])^2 &=& -2Cov[XY] -2E[X]E[Y] + 2(E[Y] - \\beta_1E[X])E[X] \\\\\n",
        "   -2\\beta_1Var[X] - 2 \\beta_1(E[X])^2 &=& -2Cov[XY] -2E[X]E[Y] + 2E[X]E[Y] - 2\\beta_1E[X]^2 \\\\\n",
        "   -2\\beta_1Var[X] - 2\\beta_1(E[X])^2 &=& -2Cov[XY] - 2\\beta_1E[X]^2 \\\\\n",
        "   -2\\beta_1Var[X]  &=&  -2Cov[XY] \\\\\n",
        "   \\beta_1 &=& Cov[XY]/Var[X]\n",
        "\\end{eqnarray}"
      ],
      "metadata": {
        "id": "Vo0JsNJm-Mny"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66X264ZpDF58"
      },
      "source": [
        "---\n",
        "## 2. Connecting to data (4 points)\n",
        "\n",
        "Now let's connect this to some real data. Once again we'll be using the  **unrestricted_trimmed_1_7_2020_10_50_44.csv** file from the *Homework/hcp_data* folder in the class GitHub repository.\n",
        "\n",
        "​\n",
        "This data is a portion of the [Human Connectome Project database](http://www.humanconnectomeproject.org/). It provides measures of cognitive tasks and brain morphology measurements from 1206 participants. The full description of each variable is provided in the **HCP_S1200_DataDictionary_April_20_2018.csv** file in the *Homework/hcp_data* folder in the class GitHub repository.\n",
        "\n",
        "a) Use the `setwd` and `read.csv` functions to load data from the **unrestricted_trimmed_1_7_2020_10_50_44.csv** file. Then use the `tidyverse` tools make a new dataframe `d1` that only inclues the subject ID (`Subject`), Flanker Task performance (`Flanker_Unadj`), and total grey matter volume (`FS_Total_GM_Vol`) variables and remove all _NA_ values.\n",
        "\n",
        "Use the `head` function to look at the first few rows of each data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZ0lngBjDF58",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "92edbbeb-3665-4144-e589-2730d12ed3dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 3</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Subject</th><th scope=col>Flanker_Unadj</th><th scope=col>FS_Total_GM_Vol</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>100206</td><td>130.42</td><td>807245</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>100307</td><td>112.56</td><td>664124</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>100408</td><td>121.18</td><td>726206</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>100610</td><td>126.53</td><td>762308</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>101006</td><td>101.85</td><td>579632</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>101107</td><td>107.04</td><td>665024</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A data.frame: 6 × 3\n",
              "\\begin{tabular}{r|lll}\n",
              "  & Subject & Flanker\\_Unadj & FS\\_Total\\_GM\\_Vol\\\\\n",
              "  & <int> & <dbl> & <int>\\\\\n",
              "\\hline\n",
              "\t1 & 100206 & 130.42 & 807245\\\\\n",
              "\t2 & 100307 & 112.56 & 664124\\\\\n",
              "\t3 & 100408 & 121.18 & 726206\\\\\n",
              "\t4 & 100610 & 126.53 & 762308\\\\\n",
              "\t5 & 101006 & 101.85 & 579632\\\\\n",
              "\t6 & 101107 & 107.04 & 665024\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A data.frame: 6 × 3\n",
              "\n",
              "| <!--/--> | Subject &lt;int&gt; | Flanker_Unadj &lt;dbl&gt; | FS_Total_GM_Vol &lt;int&gt; |\n",
              "|---|---|---|---|\n",
              "| 1 | 100206 | 130.42 | 807245 |\n",
              "| 2 | 100307 | 112.56 | 664124 |\n",
              "| 3 | 100408 | 121.18 | 726206 |\n",
              "| 4 | 100610 | 126.53 | 762308 |\n",
              "| 5 | 101006 | 101.85 | 579632 |\n",
              "| 6 | 101107 | 107.04 | 665024 |\n",
              "\n"
            ],
            "text/plain": [
              "  Subject Flanker_Unadj FS_Total_GM_Vol\n",
              "1 100206  130.42        807245         \n",
              "2 100307  112.56        664124         \n",
              "3 100408  121.18        726206         \n",
              "4 100610  126.53        762308         \n",
              "5 101006  101.85        579632         \n",
              "6 101107  107.04        665024         "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Set working directory\n",
        "setwd(\"Homework datasets/hcp_data\")\n",
        "\n",
        "# Load required libraries\n",
        "#library(tidyverse)\n",
        "library(ggplot2)\n",
        "library(dplyr)\n",
        "\n",
        "# Read the data\n",
        "hcp_data <- read.csv(\"unrestricted_trimmed_1_7_2020_10_50_44.csv\")\n",
        "\n",
        "# Create dataframe d1 with only the required variables and remove NA values\n",
        "d1 <- hcp_data %>%\n",
        "  select(Subject, Flanker_Unadj, FS_Total_GM_Vol) %>%\n",
        "  filter(!is.na(Subject), !is.na(Flanker_Unadj), !is.na(FS_Total_GM_Vol))\n",
        "\n",
        "# Look at the first few rows\n",
        "head(d1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3owDQ0U2Ewn"
      },
      "source": [
        "b) Now we're going to see if the solutions we proved above actually line up with the model fit that R gives us (it should...). Calculate what the $\\beta_0$ and $\\beta_1$ coefficients should be for a simple linear regression model using `Flanker_Unadj` as $Y$ and `FS_Total_GM_Vol` as $X$. Use the formulas we derived above ($\\beta_1 = Cov[XY]/Var[X]$ , $\\beta_0 = E[Y] - \\beta_1E[X]$). Then use `lm()` to compare the coefficients you calculated with the ones R gives you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWvD8shRDF5_",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "81d3395a-b9a5-4ff6-ddd7-4e9a833b7acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Manually calculated coefficients:\n",
            "beta0 (intercept): 90.25646 \n",
            "beta1 (slope): 3.109965e-05 \n",
            "\n",
            "Coefficients from lm():\n",
            "beta0 (intercept): 90.25646 \n",
            "beta1 (slope): 3.109965e-05 \n",
            "\n",
            "Difference between manual and lm() calculations:\n",
            "beta0 difference: 2.842171e-14 \n",
            "beta1 difference: 6.776264e-21 \n"
          ]
        }
      ],
      "source": [
        "# Calculate means\n",
        "x_mean <- mean(d1$FS_Total_GM_Vol)\n",
        "y_mean <- mean(d1$Flanker_Unadj)\n",
        "\n",
        "# Calculate beta1\n",
        "# beta1 = sum(xi*yi - beta0*xi) / sum(xi^2)\n",
        "# Using the formula beta1 = sum((xi - x_mean)*(yi - y_mean)) / sum((xi - x_mean)^2)\n",
        "numerator <- sum((d1$FS_Total_GM_Vol - x_mean) * (d1$Flanker_Unadj - y_mean))\n",
        "denominator <- sum((d1$FS_Total_GM_Vol - x_mean)^2)\n",
        "beta1_manual <- numerator / denominator\n",
        "\n",
        "# Calculate beta0\n",
        "# beta0 = y_mean - beta1 * x_mean\n",
        "beta0_manual <- y_mean - beta1_manual * x_mean\n",
        "\n",
        "# Print manually calculated coefficients\n",
        "cat(\"Manually calculated coefficients:\\n\")\n",
        "cat(\"beta0 (intercept):\", beta0_manual, \"\\n\")\n",
        "cat(\"beta1 (slope):\", beta1_manual, \"\\n\\n\")\n",
        "\n",
        "# Fit linear model using lm()\n",
        "model <- lm(Flanker_Unadj ~ FS_Total_GM_Vol, data = d1)\n",
        "\n",
        "# Print coefficients from lm()\n",
        "cat(\"Coefficients from lm():\\n\")\n",
        "cat(\"beta0 (intercept):\", coef(model)[1], \"\\n\")\n",
        "cat(\"beta1 (slope):\", coef(model)[2], \"\\n\")\n",
        "\n",
        "# Compare the two sets of coefficients\n",
        "cat(\"\\nDifference between manual and lm() calculations:\\n\")\n",
        "cat(\"beta0 difference:\", abs(beta0_manual - coef(model)[1]), \"\\n\")\n",
        "cat(\"beta1 difference:\", abs(beta1_manual - coef(model)[2]), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcnXbsZvDF6B"
      },
      "source": [
        "**DUE:** 5pm EST, Feb 26, 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG5swCweDF6B"
      },
      "source": [
        "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here.\n",
        "> *Someone's Name*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}